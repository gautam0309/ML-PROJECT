{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15966805",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15966805",
        "outputId": "02817e34-2f83-47a8-cc05-ef14e9202c84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Dataset 1 (Mendeley) ---\n",
            "‚úÖ Columns:\n",
            " ['Department', 'Gender', 'HSC', 'SSC', 'Income', 'Hometown', 'Computer', 'Preparation', 'Gaming', 'Attendance', 'Job', 'English', 'Extra', 'Semester', 'Last', 'Overall']\n",
            "üìä Data Types:\n",
            " Department      object\n",
            "Gender          object\n",
            "HSC            float64\n",
            "SSC            float64\n",
            "Income          object\n",
            "Hometown        object\n",
            "Computer         int64\n",
            "Preparation     object\n",
            "Gaming          object\n",
            "Attendance      object\n",
            "Job             object\n",
            "English          int64\n",
            "Extra           object\n",
            "Semester        object\n",
            "Last           float64\n",
            "Overall        float64\n",
            "dtype: object\n",
            "üîç Preview:\n",
            "                 Department  Gender   HSC   SSC                        Income  \\\n",
            "0  Business Administration    Male  4.17  4.84            Low (Below 15,000)   \n",
            "1  Business Administration  Female  4.92  5.00  Upper middle (30,000-50,000)   \n",
            "2  Business Administration    Male  5.00  4.83  Lower middle (15,000-30,000)   \n",
            "\n",
            "  Hometown  Computer        Preparation             Gaming Attendance Job  \\\n",
            "0  Village         3  More than 3 Hours           0-1 Hour   80%-100%  No   \n",
            "1     City         3           0-1 Hour           0-1 Hour   80%-100%  No   \n",
            "2  Village         3           0-1 Hour  More than 3 Hours   80%-100%  No   \n",
            "\n",
            "   English Extra Semester   Last  Overall  \n",
            "0        3   Yes      6th  3.220    3.350  \n",
            "1        3   Yes      7th  3.467    3.467  \n",
            "2        4   Yes      3rd  4.000    3.720  \n",
            "\n",
            "--- Dataset 2 (Kaggle Exams) ---\n",
            "‚úÖ Columns:\n",
            " ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course', 'math score', 'reading score', 'writing score']\n",
            "üìä Data Types:\n",
            " gender                         object\n",
            "race/ethnicity                 object\n",
            "parental level of education    object\n",
            "lunch                          object\n",
            "test preparation course        object\n",
            "math score                      int64\n",
            "reading score                   int64\n",
            "writing score                   int64\n",
            "dtype: object\n",
            "üîç Preview:\n",
            "    gender race/ethnicity parental level of education     lunch  \\\n",
            "0  female        group B           bachelor's degree  standard   \n",
            "1  female        group C                some college  standard   \n",
            "2  female        group B             master's degree  standard   \n",
            "\n",
            "  test preparation course  math score  reading score  writing score  \n",
            "0                    none          72             72             74  \n",
            "1               completed          69             90             88  \n",
            "2                    none          90             95             93  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "file_paths = {\n",
        "    \"Dataset 1 (Mendeley)\": \"Students_Performance_Mendeley.csv\",\n",
        "    \"Dataset 2 (Kaggle Exams)\": \"Students_Performance_kaggle.csv\"\n",
        "}\n",
        "\n",
        "for name, path in file_paths.items():\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    try:\n",
        "        df = pd.read_csv(path)\n",
        "        print(\"‚úÖ Columns:\\n\", df.columns.tolist())\n",
        "        print(\"üìä Data Types:\\n\", df.dtypes)\n",
        "        print(\"üîç Preview:\\n\", df.head(3))\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Could not load {name}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3fc3c10",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3fc3c10",
        "outputId": "3f8d3d3f-a4ac-4b60-bcaa-50e0d4699913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Columns:\n",
            " ['gender', 'race/ethnicity', 'parental level of education', 'lunch', 'test preparation course', 'math score', 'reading score', 'writing score']\n",
            "üìä Data Types:\n",
            " gender                         object\n",
            "race/ethnicity                 object\n",
            "parental level of education    object\n",
            "lunch                          object\n",
            "test preparation course        object\n",
            "math score                      int64\n",
            "reading score                   int64\n",
            "writing score                   int64\n",
            "dtype: object\n",
            "üîç Preview:\n",
            "    gender race/ethnicity parental level of education     lunch  \\\n",
            "0  female        group B           bachelor's degree  standard   \n",
            "1  female        group C                some college  standard   \n",
            "2  female        group B             master's degree  standard   \n",
            "\n",
            "  test preparation course  math score  reading score  writing score  \n",
            "0                    none          72             72             74  \n",
            "1               completed          69             90             88  \n",
            "2                    none          90             95             93  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "kaggle_path = \"Students_Performance_kaggle.csv\"\n",
        "\n",
        "try:\n",
        "    df_kaggle = pd.read_csv(kaggle_path)\n",
        "    print(\"‚úÖ Columns:\\n\", df_kaggle.columns.tolist())\n",
        "    print(\"üìä Data Types:\\n\", df_kaggle.dtypes)\n",
        "    print(\"üîç Preview:\\n\", df_kaggle.head(3))\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Could not load Kaggle dataset: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c49c2c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c49c2c2",
        "outputId": "a9abec69-b34b-492f-f25b-7be818243ad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         Department  gender   HSC   SSC  \\\n",
            "0           Business Administration  Female  4.92  5.00   \n",
            "1           Business Administration  Female  2.19  3.17   \n",
            "2  Computer Science and Engineering  Female  3.33  4.95   \n",
            "3  Computer Science and Engineering  Female  4.51  4.75   \n",
            "4  Computer Science and Engineering  Female  4.58  4.94   \n",
            "\n",
            "                          Income Hometown  Computer test preparation course  \\\n",
            "0   Upper middle (30,000-50,000)     City       3.0                0-1 Hour   \n",
            "1   Lower middle (15,000-30,000)  Village       3.0                0-1 Hour   \n",
            "2  Lower middle (15,000-30,000)      City       3.0                0-1 Hour   \n",
            "3   Lower middle (15,000-30,000)  Village       1.0                0-1 Hour   \n",
            "4            High (Above 50,000)  Village       3.0                0-1 Hour   \n",
            "\n",
            "              Gaming Attendance  ... Extra  Semester   Last Overall  \\\n",
            "0           0-1 Hour   80%-100%  ...   Yes       7th  3.467   3.467   \n",
            "1          2-3 Hours   80%-100%  ...   Yes       4th  3.940   3.940   \n",
            "2  More than 3 Hours  Below 40%  ...    No       2nd  1.500   1.500   \n",
            "3  More than 3 Hours    60%-79%  ...   Yes       8th  1.830   1.710   \n",
            "4  More than 3 Hours  Below 40%  ...    No       5th  1.330   1.900   \n",
            "\n",
            "   race/ethnicity  parental level of education    lunch math score  \\\n",
            "0         Missing                      Missing  Missing          0   \n",
            "1         Missing                      Missing  Missing          0   \n",
            "2         Missing                      Missing  Missing          0   \n",
            "3         Missing                      Missing  Missing          0   \n",
            "4         Missing                      Missing  Missing          0   \n",
            "\n",
            "  reading score  writing score  \n",
            "0             0              0  \n",
            "1             0              0  \n",
            "2             0              0  \n",
            "3             0              0  \n",
            "4             0              0  \n",
            "\n",
            "[5 rows x 22 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load both datasets\n",
        "mendeley_df = pd.read_csv(\"Students_Performance_Mendeley.csv\")\n",
        "kaggle_df = pd.read_csv(\"Students_Performance_kaggle.csv\")\n",
        "\n",
        "# Standardize column names to make merging easier\n",
        "mendeley_df.rename(columns={'Gender': 'gender', 'Preparation': 'test preparation course'}, inplace=True)\n",
        "\n",
        "# Merge the datasets on common columns (gender and test preparation course)\n",
        "merged_df = pd.merge(mendeley_df, kaggle_df, on=['gender', 'test preparation course'], how='outer')\n",
        "\n",
        "# Handle missing values (optional, depending on how you want to treat them)\n",
        "# For categorical columns, fill with 'Missing'\n",
        "merged_df[['gender', 'test preparation course', 'race/ethnicity', 'parental level of education', 'lunch']] = \\\n",
        "    merged_df[['gender', 'test preparation course', 'race/ethnicity', 'parental level of education', 'lunch']].fillna('Missing')\n",
        "\n",
        "# For numerical columns, fill with 0\n",
        "numerical_columns = ['HSC', 'SSC', 'math score', 'reading score', 'writing score', 'Last', 'Overall']\n",
        "merged_df[numerical_columns] = merged_df[numerical_columns].fillna(0)\n",
        "\n",
        "# Ensure correct data types for numerical columns\n",
        "merged_df['HSC'] = merged_df['HSC'].astype(float)\n",
        "merged_df['SSC'] = merged_df['SSC'].astype(float)\n",
        "merged_df['math score'] = merged_df['math score'].astype(int)\n",
        "merged_df['reading score'] = merged_df['reading score'].astype(int)\n",
        "merged_df['writing score'] = merged_df['writing score'].astype(int)\n",
        "\n",
        "# Preview the merged dataset\n",
        "print(merged_df.head())\n",
        "\n",
        "# Save the new merged dataset\n",
        "merged_df.to_csv(\"merged_student_performance.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06e0b54c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06e0b54c",
        "outputId": "47df6642-40f0-4ffb-c673-e6b7c6081daf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Model Evaluation:\n",
            "Mean Absolute Error: 0.060461078761573375\n",
            "Mean Squared Error: 0.023459389403171424\n",
            "R-squared: 0.9901894562440284\n",
            "\n",
            "Random Forest Model Evaluation:\n",
            "Mean Absolute Error: 0.046214615384615354\n",
            "Mean Squared Error: 0.024526781290635433\n",
            "R-squared: 0.9897430808232206\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Load the merged dataset\n",
        "merged_df = pd.read_csv(\"merged_student_performance.csv\")\n",
        "\n",
        "# Data Preprocessing: Encode categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_columns = ['gender', 'test preparation course', 'race/ethnicity', 'parental level of education',\n",
        "                       'lunch', 'Department', 'Hometown', 'Job', 'Extra', 'Semester']\n",
        "\n",
        "# Encoding categorical columns\n",
        "for col in categorical_columns:\n",
        "    merged_df[col] = label_encoder.fit_transform(merged_df[col])\n",
        "\n",
        "# Encoding the 'Income' column by mapping categories to numeric values\n",
        "income_mapping = {\n",
        "    'Low (Below 15,000)': 1,\n",
        "    'Upper middle (30,000-50,000)': 2,\n",
        "    'High (Above 50,000)': 3,\n",
        "    'Missing': 0\n",
        "}\n",
        "merged_df['Income'] = merged_df['Income'].map(income_mapping)\n",
        "\n",
        "# Handle time-related columns (e.g., 'Gaming' and 'Attendance') by mapping them to numeric values\n",
        "time_mapping = {\n",
        "    '0-1 Hour': 0.5,\n",
        "    '1-2 Hours': 1.5,\n",
        "    '2-3 Hours': 2.5,\n",
        "    'More than 3 Hours': 3\n",
        "}\n",
        "\n",
        "merged_df['Gaming'] = merged_df['Gaming'].map(time_mapping)\n",
        "merged_df['Attendance'] = merged_df['Attendance'].map({'80%-100%': 1, '60%-80%': 0.8, '40%-60%': 0.6, '0%-40%': 0.4})\n",
        "\n",
        "# Fill missing values with the column mean for numerical columns\n",
        "merged_df.fillna(merged_df.mean(), inplace=True)\n",
        "\n",
        "# Features (X) and Target (y)\n",
        "X = merged_df.drop(columns=['Overall'])  # Dropping target column 'Overall'\n",
        "y = merged_df['Overall']  # Target column 'Overall'\n",
        "\n",
        "# Split data into training and testing sets (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scaling numerical data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train a Linear Regression model\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_lr = lr_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the Linear Regression model\n",
        "print(\"Linear Regression Model Evaluation:\")\n",
        "print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_pred_lr)}\")\n",
        "print(f\"Mean Squared Error: {mean_squared_error(y_test, y_pred_lr)}\")\n",
        "print(f\"R-squared: {r2_score(y_test, y_pred_lr)}\")\n",
        "\n",
        "# Train a Random Forest Regressor model for comparison\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Make predictions with Random Forest\n",
        "y_pred_rf = rf_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the Random Forest model\n",
        "print(\"\\nRandom Forest Model Evaluation:\")\n",
        "print(f\"Mean Absolute Error: {mean_absolute_error(y_test, y_pred_rf)}\")\n",
        "print(f\"Mean Squared Error: {mean_squared_error(y_test, y_pred_rf)}\")\n",
        "print(f\"R-squared: {r2_score(y_test, y_pred_rf)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "945a3114",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "945a3114",
        "outputId": "d03e97da-b583-4111-b8fb-3587128fdf1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Math Dataset Head:\n",
            "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
            "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
            "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
            "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
            "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
            "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
            "\n",
            "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
            "0      4        3      4     1     1      3        6   5   6   6  \n",
            "1      5        3      3     1     1      3        4   5   5   6  \n",
            "2      4        3      2     2     3      3       10   7   8  10  \n",
            "3      3        2      2     1     1      5        2  15  14  15  \n",
            "4      4        3      2     1     2      5        4   6  10  10  \n",
            "\n",
            "[5 rows x 33 columns]\n",
            "\n",
            "Portuguese Dataset Head:\n",
            "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
            "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
            "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
            "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
            "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
            "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
            "\n",
            "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
            "0      4        3      4     1     1      3        4   0  11  11  \n",
            "1      5        3      3     1     1      3        2   9  11  11  \n",
            "2      4        3      2     2     3      3        6  12  13  12  \n",
            "3      3        2      2     1     1      5        0  14  14  14  \n",
            "4      4        3      2     1     2      5        0  11  13  13  \n",
            "\n",
            "[5 rows x 33 columns]\n",
            "\n",
            "Columns in the merged dataset: Index(['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu',\n",
            "       'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime',\n",
            "       'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery',\n",
            "       'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc',\n",
            "       'Walc', 'health', 'absences', 'G1', 'G2', 'G3'],\n",
            "      dtype='object')\n",
            "\n",
            "Merged Dataset Head:\n",
            "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
            "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
            "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
            "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
            "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
            "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
            "\n",
            "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
            "0      4        3      4     1     1      3        6   5   6   6  \n",
            "1      5        3      3     1     1      3        4   5   5   6  \n",
            "2      4        3      2     2     3      3       10   7   8  10  \n",
            "3      3        2      2     1     1      5        2  15  14  15  \n",
            "4      4        3      2     1     2      5        4   6  10  10  \n",
            "\n",
            "[5 rows x 33 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "mat_data = pd.read_csv(\"student-mat.csv\", sep=\";\")\n",
        "pro_data = pd.read_csv(\"student-por.csv\", sep=\";\")\n",
        "\n",
        "# Check the first few rows of each dataset to ensure they are loaded correctly\n",
        "print(\"Math Dataset Head:\")\n",
        "print(mat_data.head())\n",
        "\n",
        "print(\"\\nPortuguese Dataset Head:\")\n",
        "print(pro_data.head())\n",
        "\n",
        "# Merge the datasets (concatenate them)\n",
        "merged_data = pd.concat([mat_data, pro_data], ignore_index=True)\n",
        "\n",
        "# Check the columns in the merged dataset\n",
        "print(\"\\nColumns in the merged dataset:\", merged_data.columns)\n",
        "\n",
        "# Check the first few rows of the merged dataset\n",
        "print(\"\\nMerged Dataset Head:\")\n",
        "print(merged_data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1126e47",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1126e47",
        "outputId": "fe057753-c038-4235-cc6e-e3f92b9df961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged dataset saved as 'merged_student_data.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the datasets\n",
        "mat_data = pd.read_csv(\"student-mat.csv\", sep=\";\")\n",
        "pro_data = pd.read_csv(\"student-por.csv\", sep=\";\")\n",
        "\n",
        "# Merge the datasets (concatenate them)\n",
        "merged_data = pd.concat([mat_data, pro_data], ignore_index=True)\n",
        "\n",
        "# Save the merged dataset to a new CSV file\n",
        "merged_data.to_csv(\"merged_student_data.csv\", index=False, sep=\";\")\n",
        "\n",
        "# Confirm that the CSV file has been saved\n",
        "print(\"Merged dataset saved as 'merged_student_data.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c4f07d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c4f07d9",
        "outputId": "1c0721c4-e43d-49e3-ec67-f15ed75d5333"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ final.csv created successfully with all expanded fields.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load UCL dataset\n",
        "ucl = pd.read_csv(\"merged_student_data.csv\", sep=';')\n",
        "\n",
        "# Load Mendeley+Kaggle merged dataset\n",
        "mk = pd.read_csv(\"merged_student_performance.csv\")\n",
        "\n",
        "# Clean and match common fields\n",
        "ucl = ucl.rename(columns={\n",
        "    \"sex\": \"gender\",\n",
        "    \"activities\": \"Extra\",\n",
        "    \"G1\": \"math score\",\n",
        "    \"G2\": \"reading score\",\n",
        "    \"G3\": \"writing score\"\n",
        "})\n",
        "\n",
        "# Add missing columns in UCL to match Mendeley+Kaggle\n",
        "for col in mk.columns:\n",
        "    if col not in ucl.columns:\n",
        "        ucl[col] = \"Missing\"\n",
        "\n",
        "# Add missing columns in mk to match UCL (for academic + social info)\n",
        "for col in ucl.columns:\n",
        "    if col not in mk.columns:\n",
        "        mk[col] = \"Missing\"\n",
        "\n",
        "# Ensure same column order\n",
        "ucl = ucl[mk.columns]\n",
        "\n",
        "# Concatenate datasets\n",
        "final = pd.concat([ucl, mk], ignore_index=True)\n",
        "\n",
        "# Save to final.csv\n",
        "final.to_csv(\"final.csv\", index=False)\n",
        "\n",
        "print(\"‚úÖ final.csv created successfully with all expanded fields.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaf6b2cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaf6b2cf",
        "outputId": "d03f878c-fa93-4e56-b9a2-41beae449b3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R¬≤ Score: 0.9897954974137438\n",
            "Mean Squared Error: 9.757813558302088\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Load the final merged dataset\n",
        "data = pd.read_csv('final.csv')\n",
        "\n",
        "# Drop rows with missing target\n",
        "data = data[data['writing score'] != \"Missing\"]\n",
        "\n",
        "# Convert scores to numeric\n",
        "data['writing score'] = pd.to_numeric(data['writing score'], errors='coerce')\n",
        "data['math score'] = pd.to_numeric(data['math score'], errors='coerce')\n",
        "data['reading score'] = pd.to_numeric(data['reading score'], errors='coerce')\n",
        "\n",
        "# Drop rows with missing values in numerical target or features\n",
        "data.dropna(subset=['writing score', 'math score', 'reading score'], inplace=True)\n",
        "\n",
        "# Select features\n",
        "features = ['gender', 'studytime', 'failures', 'internet', 'Extra', 'math score', 'reading score']\n",
        "X = data[features]\n",
        "y = data['writing score']\n",
        "\n",
        "# Fill missing in features\n",
        "X = X.fillna('Missing')\n",
        "\n",
        "# Identify categorical and numeric columns\n",
        "categorical = X.select_dtypes(include='object').columns.tolist()\n",
        "numerical = X.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "# Preprocessing\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"cat\", OneHotEncoder(handle_unknown='ignore'), categorical),\n",
        "    (\"num\", StandardScaler(), numerical)\n",
        "])\n",
        "\n",
        "# ML Pipeline\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocess', preprocessor),\n",
        "    ('regressor', RandomForestRegressor(random_state=42))\n",
        "])\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(\"R¬≤ Score:\", r2_score(y_test, y_pred))\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39de9d8c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39de9d8c",
        "outputId": "1cb92b82-6a37-486f-b896-ca27d7d3dfff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validated R¬≤ scores: [0.78501371 0.73062734 0.94173573 0.93401872 0.74037464]\n",
            "Average R¬≤ score: 0.8263540249033342\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
        "print(\"Cross-validated R¬≤ scores:\", scores)\n",
        "print(\"Average R¬≤ score:\", scores.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c162dbad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c162dbad",
        "outputId": "b164227e-82a4-45d9-ee61-a7347f2079cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best R¬≤ Score: 0.8483232801870078\n",
            "Best Parameters: {'regressor__max_depth': 5, 'regressor__n_estimators': 200}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'regressor__n_estimators': [50, 100, 200],\n",
        "    'regressor__max_depth': [None, 5, 10],\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(model, param_grid, cv=5, scoring='r2')\n",
        "grid.fit(X, y)\n",
        "\n",
        "print(\"Best R¬≤ Score:\", grid.best_score_)\n",
        "print(\"Best Parameters:\", grid.best_params_)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}